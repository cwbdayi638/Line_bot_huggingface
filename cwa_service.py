# cwa_service.py
# -*- coding: utf-8 -*-
from __future__ import annotations
import requests
import re
import pandas as pd
from datetime import datetime, timedelta, timezone
from config import CWA_API_KEY, CWA_ALARM_API, CWA_SIGNIFICANT_API

TAIPEI_TZ = timezone(timedelta(hours=8))

# --- Helper Functions ---
def _to_float(x):
    if x is None: return None
    s = str(x).strip()
    m = re.search(r"[-+]?\d+(?:\.\d+)?", s)
    return float(m.group()) if m else None

def _parse_cwa_time(s: str) -> tuple[str, str]:
    if not s: return ("æœªçŸ¥", "æœªçŸ¥")
    try:
        dt = datetime.fromisoformat(s.replace("Z", "+00:00"))
        tw = dt.astimezone(TAIPEI_TZ).strftime("%Y-%m-%d %H:%M")
        utc = dt.astimezone(timezone.utc).strftime("%Y-%m-%d %H:%M")
        return (tw, utc)
    except Exception:
        return (s, "æœªçŸ¥")

# --- åœ°éœ‡é è­¦ (CWA_ALARM_API) ---
def fetch_cwa_alarm_list(limit: int = 5) -> str:
    """æŠ“ CWA åœ°éœ‡é è­¦ä¸¦æ ¼å¼åŒ–è¼¸å‡ºã€‚"""
    try:
        r = requests.get(CWA_ALARM_API, timeout=10)
        r.raise_for_status()
        payload = r.json()
    except Exception as e:
        return f"âŒ åœ°éœ‡é è­¦æŸ¥è©¢å¤±æ•—ï¼š{e}"

    items = payload.get("data", [])
    if not items:
        return "âœ… ç›®å‰æ²’æœ‰åœ°éœ‡é è­¦ã€‚"

    def _key(it):
        try:
            return datetime.fromisoformat(it.get("originTime", "").replace("Z", "+00:00"))
        except:
            return datetime.min.replace(tzinfo=timezone.utc)
    
    items = sorted(items, key=_key, reverse=True)
    lines = ["ğŸš¨ åœ°éœ‡é è­¦ï¼ˆæœ€æ–°ï¼‰:", "-" * 20]
    for it in items[:limit]:
        mag = _to_float(it.get("magnitudeValue"))
        depth = _to_float(it.get("depth"))
        tw_str, _ = _parse_cwa_time(it.get("originTime", ""))
        identifier = str(it.get('identifier', 'â€”')).replace('{', '{{').replace('}', '}}')
        msg_type = str(it.get('msgType', 'â€”')).replace('{', '{{').replace('}', '}}')
        msg_no = str(it.get('msgNo', 'â€”')).replace('{', '{{').replace('}', '}}')
        areas = str(it.get('alertAreas') or 'â€”').replace('{', '{{').replace('}', '}}')
        mag_str = f"{mag:.1f}" if mag is not None else "â€”"
        depth_str = f"{depth:.0f}" if depth is not None else "â€”"
        lines.append(
            f"äº‹ä»¶: {identifier} | é¡å‹: {msg_type}#{msg_no}\n"
            f"è¦æ¨¡/æ·±åº¦: M{mag_str} / {depth_str} km\n"
            f"æ™‚é–“: {tw_str}ï¼ˆå°ç£ï¼‰\n"
            f"é è­¦åœ°å€: {areas}"
        )
    return "\n\n".join(lines).strip()

# --- é¡¯è‘—æœ‰æ„Ÿåœ°éœ‡ (E-A0015-001) ---
def _parse_significant_earthquakes(obj: dict) -> pd.DataFrame:
    records = obj.get("records") or obj.get("Records") or {}
    quakes = records.get("earthquake") or records.get("Earthquake") or []
    rows = []
    for q in quakes:
        ei = q.get("EarthquakeInfo") or q.get("earthquakeInfo") or {}
        epic = ei.get("Epicenter") or ei.get("epicenter") or {}
        mag_info = ei.get("Magnitude") or ei.get("magnitude") or ei.get("EarthquakeMagnitude") or {}
        depth_raw = ei.get("FocalDepth") or ei.get("depth") or ei.get("Depth")
        mag_raw = mag_info.get("MagnitudeValue") or mag_info.get("magnitudeValue") or mag_info.get("Value") or mag_info.get("value")
        rows.append({
            "ID": q.get("EarthquakeNo"), "Time": ei.get("OriginTime"),
            "Lat": _to_float(epic.get("EpicenterLatitude") or epic.get("epicenterLatitude")),
            "Lon": _to_float(epic.get("EpicenterLongitude") or epic.get("epicenterLongitude")),
            "Depth": _to_float(depth_raw), "Magnitude": _to_float(mag_raw),
            "Location": epic.get("Location") or epic.get("location"),
            "URL": q.get("Web") or q.get("ReportURL"),
        })
    df = pd.DataFrame(rows)
    if not df.empty and "Time" in df.columns:
        time_series = pd.to_datetime(df["Time"], errors="coerce")
        if pd.api.types.is_datetime64_any_dtype(time_series):
            df["Time"] = time_series.dt.tz_localize("UTC").dt.tz_convert(TAIPEI_TZ)
    return df

def fetch_significant_earthquakes(days: int = 7, limit: int = 5) -> str:
    if not CWA_API_KEY: return "âŒ é¡¯è‘—åœ°éœ‡æŸ¥è©¢å¤±æ•—ï¼šç®¡ç†è€…å°šæœªè¨­å®š CWA_API_KEYã€‚"
    now = datetime.now(timezone.utc)
    time_from = (now - timedelta(days=days)).strftime("%Y-%m-%d")
    params = {"Authorization": CWA_API_KEY, "format": "JSON", "timeFrom": time_from}
    try:
        r = requests.get(CWA_SIGNIFICANT_API, params=params, timeout=15)
        r.raise_for_status()
        data = r.json()
        df = _parse_significant_earthquakes(data)
        if df.empty: return f"âœ… éå» {days} å¤©å…§æ²’æœ‰é¡¯è‘—æœ‰æ„Ÿåœ°éœ‡å ±å‘Šã€‚"
        df = df.sort_values(by="Time", ascending=False).head(limit)
        lines = [f"ğŸš¨ CWA æœ€æ–°é¡¯è‘—æœ‰æ„Ÿåœ°éœ‡ (è¿‘{days}å¤©å…§):", "-" * 20]
        for _, row in df.iterrows():
            mag_str = f"{row['Magnitude']:.1f}" if pd.notna(row['Magnitude']) else "â€”"
            depth_str = f"{row['Depth']:.0f}" if pd.notna(row['Depth']) else "â€”"
            lines.append(
                f"æ™‚é–“: {row['Time'].strftime('%Y-%m-%d %H:%M') if pd.notna(row['Time']) else 'â€”'}\n"
                f"åœ°é»: {row['Location'] or 'â€”'}\n"
                f"è¦æ¨¡: M{mag_str} | æ·±åº¦: {depth_str} km\n"
                f"å ±å‘Š: {row['URL'] or 'ç„¡'}"
            )
        return "\n\n".join(lines)
    except Exception as e:
        return f"âŒ é¡¯è‘—åœ°éœ‡æŸ¥è©¢å¤±æ•—ï¼š{e}"

# --- æœ€æ–°ä¸€ç­†é¡¯è‘—åœ°éœ‡ ---
def fetch_latest_significant_earthquake() -> dict | None:
    """å¾ CWA ç²å–æœ€æ–°ä¸€ç­†é¡¯è‘—åœ°éœ‡ï¼Œä¸¦é‡ç”¨ç¾æœ‰çš„è§£æé‚è¼¯"""
    if not CWA_API_KEY:
        raise ValueError("éŒ¯èª¤ï¼šå°šæœªè¨­å®š CWA_API_KEY Secretã€‚")
    
    now = datetime.now(timezone.utc)
    time_from = (now - timedelta(days=2)).strftime("%Y-%m-%dT%H:%M:%S")
    params = {"Authorization": CWA_API_KEY, "format": "JSON", "limit": 1}
    
    r = requests.get(CWA_SIGNIFICANT_API, params=params, timeout=15)
    r.raise_for_status()
    data = r.json()
    df = _parse_significant_earthquakes(data)
    if df.empty:
        return None

    latest_eq_data = df.sort_values(by="Time", ascending=False).iloc[0].to_dict()
    
    quakes = data.get("records", {}).get("Earthquake", [])
    if quakes:
        latest_eq_data["ImageURL"] = quakes[0].get("ReportImageURI")

    if pd.notna(latest_eq_data.get("Time")):
        latest_eq_data["TimeStr"] = latest_eq_data["Time"].strftime('%Y-%m-%d %H:%M')

    return latest_eq_data
